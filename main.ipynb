{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output, display # Para plots dinamicos no notebook\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from threading import Thread, Semaphore\n",
        "import os, h5py, torch, random, time\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from scipy.ndimage import zoom # Caso precise reduzir a imagem\n",
        "from logger import log\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testar funcionamento dos algorítmos (em algum momento o kernel pode quebrar e isso daqui verifica se quebrou ou não)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P0gayq3v4rND"
      },
      "outputs": [],
      "source": [
        "model = nn.Linear(10, 2).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D-UlSDNnNy81"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SpectrogramCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SpectrogramCNN, self).__init__()\n",
        "\n",
        "        conv1 = 256\n",
        "        conv2 = 64\n",
        "        conv3 = 32\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, conv1, kernel_size=10, stride=(5, 5), padding=10),\n",
        "            nn.BatchNorm2d(conv1),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.AvgPool2d(4),\n",
        "\n",
        "            nn.Conv2d(conv1, conv2, kernel_size=3, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(conv2),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.AvgPool2d(4),\n",
        "\n",
        "            nn.Conv2d(conv2, conv3, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(conv3),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.AvgPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(544, 128),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Dropout(0.3),\n",
        "            # nn.Linear(500, 128),\n",
        "            # nn.LeakyReLU(negative_slope=0.01),\n",
        "            # nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Separar train de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_test_h5_labels(): # Utilizei esse pois precisava economizar na memória, então embaralhos os patchs e n os dados\n",
        "    dir_base = \"musicas\"\n",
        "    dir_h5 = \"h5\"\n",
        "\n",
        "    estilos = os.listdir(dir_base)\n",
        "    ref_estilos = estilos.copy()\n",
        "\n",
        "    h5_train_items_path = []\n",
        "    train_labels = []\n",
        "\n",
        "    h5_test_items_path = []\n",
        "    test_labels = []\n",
        "\n",
        "    for estilo in estilos:\n",
        "        if estilo == \"apenas_h5\" or \".rar\" in estilo:\n",
        "            continue\n",
        "        train_path = os.path.join(dir_base, estilo, dir_h5, \"train\")\n",
        "        test_path = os.path.join(dir_base, estilo, dir_h5, \"test\")\n",
        "\n",
        "        train_specs_names = os.listdir(train_path)\n",
        "        for h5_spec in train_specs_names:\n",
        "            h5_spec_path = os.path.join(train_path, h5_spec)\n",
        "            h5_train_items_path.append(h5_spec_path)\n",
        "            train_labels.append(ref_estilos.index(estilo))\n",
        "\n",
        "        test_spec_names = os.listdir(test_path)\n",
        "        for h5_spec in test_spec_names:\n",
        "            h5_spec_path = os.path.join(test_path, h5_spec)\n",
        "            h5_test_items_path.append(h5_spec_path)\n",
        "            test_labels.append(ref_estilos.index(estilo))\n",
        "\n",
        "    train_combinado = list(zip(h5_train_items_path, train_labels))\n",
        "    test_combinado = list(zip(h5_test_items_path, test_labels))\n",
        "\n",
        "    random.shuffle(train_combinado)\n",
        "    random.shuffle(test_combinado)\n",
        "\n",
        "    h5_train_items_path, train_labels = zip(*train_combinado)\n",
        "    h5_test_items_path, test_labels = zip(*test_combinado)\n",
        "\n",
        "    h5_train_items_path = list(h5_train_items_path)\n",
        "    train_labels = list(train_labels)\n",
        "\n",
        "    h5_test_items_path = list(h5_test_items_path)\n",
        "    test_labels = list(test_labels)\n",
        "\n",
        "    return h5_train_items_path, train_labels, h5_test_items_path, test_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ler h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_h5_data(h5_item, zoom_factor=None, time_cut=None):\n",
        "    with h5py.File(h5_item, \"r\") as f:\n",
        "        data = f[\"data\"]\n",
        "        data = data[:]\n",
        "        if time_cut is not None:\n",
        "            data = data[:, :, data.shape[2]//time_cut:]\n",
        "        \n",
        "        if zoom_factor is not None:\n",
        "            data = zoom(data, zoom_factor)\n",
        "\n",
        "        return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom dataloader com threads\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ThreadDataloader:\n",
        "\n",
        "  def __init__(self, train_urls: list, train_labels, test_urls: list, test_labels, batch_size, device, batch_multipl=3, zoom_factor=None, time_cut=None):\n",
        "    self.train_urls = train_urls\n",
        "    self.train_labels = train_labels\n",
        "    self.test_urls = test_urls\n",
        "    self.test_labels = test_labels\n",
        "\n",
        "    self.zoom_factor = zoom_factor\n",
        "    self.time_cut = time_cut\n",
        "    self.stop_threads = False\n",
        "    self.device = device\n",
        "\n",
        "    self.loaded_train_data = []\n",
        "    self.loaded_test_data = []\n",
        "    self.loaded_train_labels = []\n",
        "    self.loaded_test_labels = []\n",
        "\n",
        "    self.batch_size = batch_size\n",
        "    self.max_train_batches = len(train_urls)//batch_size\n",
        "    self.max_test_batches = len(test_urls)//batch_size\n",
        "    self.actual_train_batch = 0\n",
        "    self.actual_test_batch = 0\n",
        "    self.max_len = self.batch_size*batch_multipl\n",
        "    self.train_semas = Semaphore(self.max_len)\n",
        "    self.test_semas = Semaphore(self.max_len)\n",
        "    self.mutex = Semaphore()\n",
        "\n",
        "  def free_train(self):\n",
        "    self.stop_threads = True\n",
        "    self.mutex.release()\n",
        "    self.train_semas.release()\n",
        "\n",
        "  def free_test(self):\n",
        "    self.stop_threads = True\n",
        "    self.mutex.release()\n",
        "    self.test_semas.release()\n",
        "\n",
        "\n",
        "  def stop(self):\n",
        "    self.free_train()\n",
        "    self.free_test()\n",
        "\n",
        "  def collect_train(self):\n",
        "    while not self.stop_threads:\n",
        "      for train_url, train_label in zip(self.train_urls, self.train_labels):\n",
        "        if self.stop_threads:\n",
        "          break\n",
        "        data = read_h5_data(train_url, self.zoom_factor, self.time_cut)\n",
        "        self.mutex.acquire()\n",
        "        self.loaded_train_data.append(data)\n",
        "        self.loaded_train_labels.append(train_label)\n",
        "        self.mutex.release()\n",
        "        self.train_semas.acquire()\n",
        "\n",
        "  def collect_test(self):\n",
        "    while not self.stop_threads:\n",
        "      for test_url, test_label in zip(self.test_urls, self.test_labels):\n",
        "        if self.stop_threads:\n",
        "          break\n",
        "        data = read_h5_data(test_url, self.zoom_factor, self.time_cut)\n",
        "        self.mutex.acquire()\n",
        "        self.loaded_test_data.append(data)\n",
        "        self.loaded_test_labels.append(test_label)\n",
        "        self.mutex.release()\n",
        "        self.test_semas.acquire()\n",
        "\n",
        "  def get_train_batch(self):\n",
        "    while len(self.loaded_train_data) < self.batch_size:\n",
        "      time.sleep(0.5)\n",
        "\n",
        "    self.mutex.acquire()\n",
        "    train_data = []\n",
        "    train_labels = []\n",
        "    for _ in range(self.batch_size):\n",
        "      train_data.append(self.loaded_train_data.pop(0))\n",
        "      train_labels.append(self.loaded_train_labels.pop(0))\n",
        "      self.train_semas.release()\n",
        "\n",
        "    self.mutex.release()\n",
        "    self.actual_train_batch = (self.actual_train_batch + 1) % (self.max_train_batches)\n",
        "\n",
        "    batch_end = self.actual_train_batch == 0\n",
        "\n",
        "    return torch.tensor(np.array(train_data), device=self.device), torch.tensor(np.array(train_labels), device=self.device), batch_end\n",
        "\n",
        "  def get_test_batch(self):\n",
        "    while len(self.loaded_test_data) < self.batch_size:\n",
        "      time.sleep(0.5)\n",
        "\n",
        "    self.mutex.acquire()\n",
        "    test_data = []\n",
        "    test_labels = []\n",
        "    for _ in range(self.batch_size):\n",
        "      test_data.append(self.loaded_test_data.pop(0))\n",
        "      test_labels.append(self.loaded_test_labels.pop(0))\n",
        "      self.test_semas.release()\n",
        "\n",
        "    self.mutex.release()\n",
        "    self.actual_test_batch = (self.actual_test_batch + 1) % (self.max_test_batches)\n",
        "\n",
        "    batch_end = self.actual_test_batch == 0\n",
        "\n",
        "    return torch.tensor(np.array(test_data), device=self.device), torch.tensor(np.array(test_labels), device=self.device), batch_end\n",
        "\n",
        "  def train_len(self):\n",
        "   self.mutex.acquire()\n",
        "   length = len(self.loaded_train_data)\n",
        "   self.mutex.release()\n",
        "   return length\n",
        "\n",
        "  def test_len(self):\n",
        "   self.mutex.acquire()\n",
        "   length = len(self.loaded_test_data)\n",
        "   self.mutex.release()\n",
        "   return length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Função de treino"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_step(modelo: SpectrogramCNN, thread_dataloader: ThreadDataloader):\n",
        "    modelo.train()\n",
        "    total_loss = 0\n",
        "    batch_atual = 0\n",
        "    stop_train = False\n",
        "\n",
        "    while not stop_train:\n",
        "        while len(thread_dataloader.loaded_train_data) < thread_dataloader.batch_size:\n",
        "            log(\n",
        "                f\"Treino {thread_dataloader.actual_train_batch}/{thread_dataloader.max_train_batches}\",\n",
        "                f\"Coletando {thread_dataloader.train_len()} items carregados em memória - Loss: {total_loss/(thread_dataloader.actual_train_batch if thread_dataloader.actual_train_batch != 0 else thread_dataloader.max_train_batches)}\",\n",
        "                thread_dataloader.actual_train_batch,\n",
        "                thread_dataloader.max_train_batches,\n",
        "                progress_char=\"+\",\n",
        "                void_char=\" \"\n",
        "            )\n",
        "            time.sleep(0.5)\n",
        "\n",
        "        batch_data, batch_labels, stop_train = thread_dataloader.get_train_batch()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        log(\n",
        "            f\"Treino {thread_dataloader.actual_train_batch}/{thread_dataloader.max_train_batches}\",\n",
        "            f\"Model predict {thread_dataloader.train_len()} items carregados em memória - Loss: {total_loss/(thread_dataloader.actual_train_batch if thread_dataloader.actual_train_batch != 0 else thread_dataloader.max_train_batches)}\",\n",
        "            thread_dataloader.actual_train_batch,\n",
        "            thread_dataloader.max_train_batches,\n",
        "            progress_char=\"+\",\n",
        "            void_char=\" \"\n",
        "        )\n",
        "        outputs = modelo(batch_data)\n",
        "        log(\n",
        "            f\"Treino {thread_dataloader.actual_train_batch}/{thread_dataloader.max_train_batches}\",\n",
        "            f\"Loss calc {thread_dataloader.train_len()} items carregados em memória - Loss: {total_loss/(thread_dataloader.actual_train_batch if thread_dataloader.actual_train_batch != 0 else thread_dataloader.max_train_batches)}\",\n",
        "            thread_dataloader.actual_train_batch,\n",
        "            thread_dataloader.max_train_batches,\n",
        "            progress_char=\"+\",\n",
        "            void_char=\" \"\n",
        "        )\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        log(\n",
        "            f\"Treino {thread_dataloader.actual_train_batch}/{thread_dataloader.max_train_batches}\",\n",
        "            f\"Loss backward {thread_dataloader.train_len()} item carregados em memórias - Loss: {total_loss/(thread_dataloader.actual_train_batch if thread_dataloader.actual_train_batch != 0 else thread_dataloader.max_train_batches)}\",\n",
        "            thread_dataloader.actual_train_batch,\n",
        "            thread_dataloader.max_train_batches,\n",
        "            progress_char=\"+\",\n",
        "            void_char=\" \"\n",
        "        )\n",
        "        loss.backward()\n",
        "        log(\n",
        "            f\"Treino {thread_dataloader.actual_train_batch}/{thread_dataloader.max_train_batches}\",\n",
        "            f\"Optimizer step {thread_dataloader.train_len()} items carregados em memória - Loss: {total_loss/(thread_dataloader.actual_train_batch if thread_dataloader.actual_train_batch != 0 else thread_dataloader.max_train_batches)}\",\n",
        "            thread_dataloader.actual_train_batch,\n",
        "            thread_dataloader.max_train_batches,\n",
        "            progress_char=\"+\",\n",
        "            void_char=\" \"\n",
        "        )\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        log(\n",
        "          f\"Treino {thread_dataloader.actual_train_batch}/{thread_dataloader.max_train_batches}\",\n",
        "          f\"{thread_dataloader.train_len()} items carregados em memória - Loss: {total_loss/(thread_dataloader.actual_train_batch if thread_dataloader.actual_train_batch != 0 else thread_dataloader.max_train_batches)}\",\n",
        "          thread_dataloader.actual_train_batch,\n",
        "          thread_dataloader.max_train_batches,\n",
        "          progress_char=\"+\",\n",
        "          void_char=\" \"\n",
        "        )\n",
        "\n",
        "    avg_loss = total_loss / thread_dataloader.max_train_batches\n",
        "    log(\n",
        "\t\tf\"Treino {thread_dataloader.actual_train_batch}/{thread_dataloader.max_train_batches}\",\n",
        "\t\tf\"{thread_dataloader.train_len()} items - Loss: {total_loss/thread_dataloader.max_train_batches}\",\n",
        "\t\tthread_dataloader.actual_train_batch,\n",
        "\t\tthread_dataloader.max_train_batches,\n",
        "\t\tprogress_char=\"+\",\n",
        "\t\tvoid_char=\" \"\n",
        "\t)\n",
        "    return avg_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Função de teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_step(modelo: SpectrogramCNN, thread_dataloader: ThreadDataloader):\n",
        "    modelo.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    stop_test = False\n",
        "\n",
        "    while not stop_test:\n",
        "        with torch.no_grad():\n",
        "            while len(thread_dataloader.loaded_test_data) < thread_dataloader.batch_size:\n",
        "                log(\n",
        "                    f\"Teste {thread_dataloader.actual_test_batch}/{thread_dataloader.max_test_batches}\",\n",
        "                    f\"Coletando {thread_dataloader.test_len()} items carreagados em memória - Loss {total_loss/(thread_dataloader.actual_test_batch if thread_dataloader.actual_test_batch != 0 else thread_dataloader.max_test_batches)}\",\n",
        "                    thread_dataloader.actual_test_batch,\n",
        "                    thread_dataloader.max_test_batches,\n",
        "                    progress_char=\"H\",\n",
        "                    void_char=\"-\"\n",
        "                )\n",
        "                time.sleep(0.5)\n",
        "            \n",
        "            batch_data, batch_labels, stop_test = thread_dataloader.get_test_batch()\n",
        "\n",
        "            log(\n",
        "                f\"Teste {thread_dataloader.actual_test_batch}/{thread_dataloader.max_test_batches}\",\n",
        "                f\"Predict {thread_dataloader.test_len()} items carreagados em memória - Loss {total_loss/(thread_dataloader.actual_test_batch if thread_dataloader.actual_test_batch != 0 else thread_dataloader.max_test_batches)}\",\n",
        "                thread_dataloader.actual_test_batch,\n",
        "                thread_dataloader.max_test_batches,\n",
        "                progress_char=\"H\",\n",
        "                void_char=\"-\"\n",
        "            )\n",
        "            outputs = modelo(batch_data)\n",
        "            log(\n",
        "                f\"Teste {thread_dataloader.actual_test_batch}/{thread_dataloader.max_test_batches}\",\n",
        "                f\"Loss calc {thread_dataloader.test_len()} items carreagados em memória - Loss {total_loss/(thread_dataloader.actual_test_batch if thread_dataloader.actual_test_batch != 0 else thread_dataloader.max_test_batches)}\",\n",
        "                thread_dataloader.actual_test_batch,\n",
        "                thread_dataloader.max_test_batches,\n",
        "                progress_char=\"H\",\n",
        "                void_char=\"-\"\n",
        "            )\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += batch_labels.size(0)\n",
        "            correct += (predicted == batch_labels).sum().item()\n",
        "\n",
        "            y_true.extend(batch_labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "            log(\n",
        "                f\"Teste {thread_dataloader.actual_test_batch}/{thread_dataloader.max_test_batches}\",\n",
        "                f\"{thread_dataloader.test_len()} items carreagados em memória - Loss {total_loss/(thread_dataloader.actual_test_batch if thread_dataloader.actual_test_batch != 0 else thread_dataloader.max_test_batches)}\",\n",
        "                thread_dataloader.actual_test_batch,\n",
        "                thread_dataloader.max_test_batches,\n",
        "                progress_char=\"H\",\n",
        "                void_char=\"-\"\n",
        "            )\n",
        "\n",
        "    log(\n",
        "        f\"Teste {thread_dataloader.actual_test_batch}/{thread_dataloader.max_test_batches}\",\n",
        "        f\"End {thread_dataloader.test_len()} items carreagados em memória - Loss {total_loss/(thread_dataloader.actual_test_batch if thread_dataloader.actual_test_batch != 0 else thread_dataloader.max_test_batches)}\",\n",
        "        thread_dataloader.actual_test_batch,\n",
        "        thread_dataloader.max_test_batches,\n",
        "        progress_char=\"H\",\n",
        "        void_char=\"-\"\n",
        "    )\n",
        "\n",
        "    return total_loss, y_true, y_pred, correct, total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Base para plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "losses = []\n",
        "accurracy_test = []\n",
        "epochs = []\n",
        "plt.ion()\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
        "line_losses, = ax1.plot(epochs, losses, label='Train Loss')\n",
        "line_accurracy_test, = ax2.plot(epochs, accurracy_test, label='Test Loss')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Treino e teste sendo efetuados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 842
        },
        "id": "LHtex5ktO4yh",
        "outputId": "3427ea08-450b-4adf-b433-6e842debe258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Aguardando 10s\n",
            "Modelo\n",
            "SpectrogramCNN(\n",
            "  (conv_layers): Sequential(\n",
            "    (0): Conv2d(1, 256, kernel_size=(10, 10), stride=(5, 5), padding=(10, 10))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.01)\n",
            "    (3): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "    (4): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): LeakyReLU(negative_slope=0.01)\n",
            "    (7): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "    (8): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.01)\n",
            "    (11): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  )\n",
            "  (fc_layers): Sequential(\n",
            "    (0): Linear(in_features=544, out_features=128, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): Dropout(p=0.3, inplace=False)\n",
            "    (3): Linear(in_features=128, out_features=11, bias=True)\n",
            "  )\n",
            ")\n",
            "Epoca: 1\n",
            "Treino 0/94  [                    ]  13 items - Loss: 2.2800461129939302               9939302                               "
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (4,) and arg 1 with shape (3,).",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m line_losses.set_xdata(epochs)\n\u001b[32m     44\u001b[39m line_losses.set_ydata(losses)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43max1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrelim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m ax1.autoscale()\n\u001b[32m     47\u001b[39m ax1.set_title(\u001b[33m\"\u001b[39m\u001b[33mTraining Loss\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projeto_ia/venv/lib/python3.12/site-packages/matplotlib/axes/_base.py:2593\u001b[39m, in \u001b[36m_AxesBase.relim\u001b[39m\u001b[34m(self, visible_only)\u001b[39m\n\u001b[32m   2591\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m visible_only \u001b[38;5;129;01mor\u001b[39;00m artist.get_visible():\n\u001b[32m   2592\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(artist, mlines.Line2D):\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_line_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2594\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(artist, mpatches.Patch):\n\u001b[32m   2595\u001b[39m         \u001b[38;5;28mself\u001b[39m._update_patch_limits(artist)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projeto_ia/venv/lib/python3.12/site-packages/matplotlib/axes/_base.py:2440\u001b[39m, in \u001b[36m_AxesBase._update_line_limits\u001b[39m\u001b[34m(self, line)\u001b[39m\n\u001b[32m   2436\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_line_limits\u001b[39m(\u001b[38;5;28mself\u001b[39m, line):\n\u001b[32m   2437\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2438\u001b[39m \u001b[33;03m    Figures out the data limit of the given line, updating `.Axes.dataLim`.\u001b[39;00m\n\u001b[32m   2439\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2440\u001b[39m     path = \u001b[43mline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2441\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m path.vertices.size == \u001b[32m0\u001b[39m:\n\u001b[32m   2442\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projeto_ia/venv/lib/python3.12/site-packages/matplotlib/lines.py:1052\u001b[39m, in \u001b[36mLine2D.get_path\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the `~matplotlib.path.Path` associated with this line.\"\"\"\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._invalidy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._invalidx:\n\u001b[32m-> \u001b[39m\u001b[32m1052\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrecache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._path\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projeto_ia/venv/lib/python3.12/site-packages/matplotlib/lines.py:698\u001b[39m, in \u001b[36mLine2D.recache\u001b[39m\u001b[34m(self, always)\u001b[39m\n\u001b[32m    695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    696\u001b[39m     y = \u001b[38;5;28mself\u001b[39m._y\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m \u001b[38;5;28mself\u001b[39m._xy = np.column_stack(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m).astype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m    699\u001b[39m \u001b[38;5;28mself\u001b[39m._x, \u001b[38;5;28mself\u001b[39m._y = \u001b[38;5;28mself\u001b[39m._xy.T  \u001b[38;5;66;03m# views\u001b[39;00m\n\u001b[32m    701\u001b[39m \u001b[38;5;28mself\u001b[39m._subslice = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projeto_ia/venv/lib/python3.12/site-packages/numpy/lib/_stride_tricks_impl.py:544\u001b[39m, in \u001b[36mbroadcast_arrays\u001b[39m\u001b[34m(subok, *args)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[32m    538\u001b[39m \u001b[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[32m    540\u001b[39m \u001b[38;5;66;03m#                  order='C').itviews\u001b[39;00m\n\u001b[32m    542\u001b[39m args = [np.array(_m, copy=\u001b[38;5;28;01mNone\u001b[39;00m, subok=subok) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m--> \u001b[39m\u001b[32m544\u001b[39m shape = \u001b[43m_broadcast_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    546\u001b[39m result = [array \u001b[38;5;28;01mif\u001b[39;00m array.shape == shape\n\u001b[32m    547\u001b[39m           \u001b[38;5;28;01melse\u001b[39;00m _broadcast_to(array, shape, subok=subok, readonly=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    548\u001b[39m                           \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projeto_ia/venv/lib/python3.12/site-packages/numpy/lib/_stride_tricks_impl.py:419\u001b[39m, in \u001b[36m_broadcast_shape\u001b[39m\u001b[34m(*args)\u001b[39m\n\u001b[32m    414\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[33;03msupplied arrays against each other.\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[38;5;66;03m# consistently\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m b = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args), \u001b[32m31\u001b[39m):\n\u001b[32m    422\u001b[39m     \u001b[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[32m    423\u001b[39m     \u001b[38;5;66;03m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[32m    424\u001b[39m     \u001b[38;5;66;03m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
            "\u001b[31mValueError\u001b[39m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (4,) and arg 1 with shape (3,)."
          ]
        }
      ],
      "source": [
        "caminho_das_musicas = \"./musicas\"\n",
        "dir_base = caminho_das_musicas\n",
        "dir_h5 = \"h5\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "zoom_factor = (1, 1, 1)\n",
        "zoom_factor = None\n",
        "batch_size = 20\n",
        "time_cut = None\n",
        "\n",
        "h5_train_items_path, train_labels, h5_test_items_path, test_labels = train_test_h5_labels()\n",
        "dataloader = ThreadDataloader(h5_train_items_path, train_labels, h5_test_items_path, test_labels, batch_size, device, zoom_factor=zoom_factor, time_cut=time_cut, batch_multipl=100)\n",
        "# dataloader.collect_train()\n",
        "collect_train_thread = Thread(target=dataloader.collect_train)\n",
        "collect_test_thread = Thread(target=dataloader.collect_test)\n",
        "collect_train_thread.start()\n",
        "collect_test_thread.start()\n",
        "\n",
        "print(\"Aguardando 10s\")\n",
        "# time.sleep(10)\n",
        "\n",
        "print(\"Modelo\", flush=True)\n",
        "estilos = os.listdir(dir_base)\n",
        "ref_estilos = estilos.copy()\n",
        "modelo = SpectrogramCNN(len(ref_estilos))\n",
        "modelo.to(device)\n",
        "# print(modelo, flush=True)\n",
        "\n",
        "optimizer = torch.optim.AdamW(modelo.parameters(), lr=0.0001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 1000\n",
        "for epoch in range(1, num_epochs):\n",
        "    print(f\"Epoca: {epoch}\", flush=True)\n",
        "    if len(epochs) < 30:\n",
        "        epochs.append(epoch+1)\n",
        "\n",
        "    avg_loss = train_step(modelo, dataloader)\n",
        "    losses.append(avg_loss)\n",
        "    if len(losses) > 30:\n",
        "        losses.pop(0)\n",
        "    line_losses.set_xdata(epochs)\n",
        "    line_losses.set_ydata(losses)\n",
        "    ax1.relim()\n",
        "    ax1.autoscale()\n",
        "    ax1.set_title(\"Training Loss\")\n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    display(fig)\n",
        "\n",
        "    total_loss, y_true, y_pred, correct, total = test_step(modelo, dataloader)\n",
        "\n",
        "    avg_test_loss = total_loss / len(h5_test_items_path)\n",
        "    accuracy = 100 * correct / total\n",
        "    accurracy_test.append(accuracy)\n",
        "    if len(accurracy_test) > 30:\n",
        "        accurracy_test.pop(0)\n",
        "    line_accurracy_test.set_xdata(epochs)\n",
        "    line_accurracy_test.set_ydata(accurracy_test)\n",
        "    ax2.relim()\n",
        "    ax2.autoscale()\n",
        "    ax2.set_title(\"Testing accuracy\")\n",
        "    ax2.set_xlabel(\"Epoch\")\n",
        "    ax2.set_ylabel(\"Accuracy\")\n",
        "\n",
        "    ax3.clear()\n",
        "    ax3.set_title(\"Confusion Matrix\")\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax3,\n",
        "                xticklabels=ref_estilos, yticklabels=ref_estilos, cbar=False)\n",
        "    ax3.set_xlabel(\"Predicted\")\n",
        "    ax3.set_ylabel(\"True\")\n",
        "\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    display(fig)\n",
        "\n",
        "    print(f\"Epoch {epoch}, Loss:: Train {avg_loss:.4f} Test {avg_test_loss:.4f}\", flush=True)\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\", flush=True)\n",
        "    torch.save(modelo.state_dict(), f\"modelo.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataloader.stop()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
